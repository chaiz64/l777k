{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéôÔ∏è Faster-Whisper-XXL Optimized Transcription\n",
        "\n",
        "A user-friendly interface for transcribing Japanese audio/video files using optimized Faster-Whisper-XXL settings.\n",
        "\n",
        "**Features:**\n",
        "- üöÄ Optimized for Japanese language transcription\n",
        "- üéØ Medium model for best speed/quality balance\n",
        "- üîß Adjustable parameters\n",
        "- üìÅ Multiple input sources (Google Drive, Upload, Local)\n",
        "- üìä Real-time progress tracking\n",
        "- üíæ Automatic SRT and JSON output\n",
        "\n",
        "**Hardware Optimized for:**\n",
        "- RTX 2080 GPU (8GB VRAM)\n",
        "- i9-9000K CPU (16 threads)\n",
        "- 32GB RAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üîß Setup Environment\n",
        "#@markdown Install required packages and setup Faster-Whisper-XXL\n",
        "\n",
        "print(\"üöÄ Setting up environment...\")\n",
        "\n",
        "# Install required packages\n",
        "!pip install faster-whisper torch torchvision torchaudio --quiet\n",
        "!pip install ffmpeg-python --quiet\n",
        "!apt-get update && apt-get install -y ffmpeg --quiet\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import faster_whisper\n",
        "import ffmpeg\n",
        "from pathlib import Path\n",
        "from google.colab import files, drive\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Check GPU availability\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"‚úÖ Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üìÅ Mount Google Drive (Optional)\n",
        "#@markdown Mount your Google Drive to access files\n",
        "\n",
        "mount_drive = False #@param {type:\"boolean\"}\n",
        "\n",
        "if mount_drive:\n",
        "    print(\"üîó Mounting Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"‚úÖ Google Drive mounted at /content/drive\")\n",
        "    print(\"üìÇ Your files are accessible at: /content/drive/MyDrive/\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è Google Drive not mounted. You can still upload files directly.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üì§ Upload Files\n",
        "#@markdown Upload audio/video files for transcription\n",
        "\n",
        "print(\"üì§ Upload your audio/video files...\")\n",
        "print(\"Supported formats: MP3, WAV, MP4, MKV, AVI, etc.\")\n",
        "\n",
        "# Create upload directory\n",
        "upload_dir = Path(\"/content/uploads\")\n",
        "upload_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Upload files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move uploaded files to upload directory\n",
        "uploaded_files = []\n",
        "for filename, content in uploaded.items():\n",
        "    file_path = upload_dir / filename\n",
        "    with open(file_path, 'wb') as f:\n",
        "        f.write(content)\n",
        "    uploaded_files.append(str(file_path))\n",
        "    print(f\"‚úÖ Uploaded: {filename}\")\n",
        "\n",
        "if uploaded_files:\n",
        "    print(f\"\\nüìÅ Files ready for processing: {len(uploaded_files)} file(s)\")\n",
        "    for f in uploaded_files:\n",
        "        print(f\"  - {Path(f).name}\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è No files uploaded. You can also specify file paths manually.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title ‚öôÔ∏è Transcription Settings\n",
        "#@markdown Configure transcription parameters\n",
        "\n",
        "# Model settings\n",
        "model_size = \"medium\" #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large-v2\", \"large-v3\"] {type:\"string\"}\n",
        "language = \"ja\" #@param [\"ja\", \"en\", \"zh\", \"ko\", \"auto\"] {type:\"string\"}\n",
        "\n",
        "# Processing settings\n",
        "compute_type = \"float16\" #@param [\"int8\", \"float16\", \"float32\"] {type:\"string\"}\n",
        "batch_size = 16 #@param {type:\"slider\", min:1, max:32, step:1}\n",
        "num_workers = 2 #@param {type:\"slider\", min:1, max:8, step:1}\n",
        "\n",
        "# VAD settings\n",
        "vad_filter = True #@param {type:\"boolean\"}\n",
        "vad_threshold = 0.5 #@param {type:\"slider\", min:0.1, max:1.0, step:0.1}\n",
        "\n",
        "# Output settings\n",
        "output_formats = [\"srt\", \"json\", \"text\"] #@param {type:\"raw\"}\n",
        "\n",
        "print(\"‚öôÔ∏è Transcription Settings:\")\n",
        "print(f\"üéØ Model: {model_size}\")\n",
        "print(f\"üåè Language: {language}\")\n",
        "print(f\"üî¢ Compute Type: {compute_type}\")\n",
        "print(f\"üì¶ Batch Size: {batch_size}\")\n",
        "print(f\"üë∑ Workers: {num_workers}\")\n",
        "print(f\"üéôÔ∏è VAD Filter: {vad_filter}\")\n",
        "print(f\"üìä VAD Threshold: {vad_threshold}\")\n",
        "print(f\"üìÑ Output Formats: {', '.join(output_formats)}\")\n",
        "\n",
        "# Create output directory\n",
        "output_dir = Path(\"/content/output\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "print(f\"üìÇ Output directory: {output_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üéØ File Selection\n",
        "#@markdown Select files to process\n",
        "\n",
        "# Manual file path input\n",
        "manual_files = \"\" #@param {type:\"string\"}\n",
        "#@markdown Enter file paths separated by commas, or leave empty to use uploaded files\n",
        "\n",
        "# Determine files to process\n",
        "files_to_process = []\n",
        "\n",
        "if manual_files.strip():\n",
        "    # Parse manual file paths\n",
        "    manual_paths = [f.strip() for f in manual_files.split(',') if f.strip()]\n",
        "    for path_str in manual_paths:\n",
        "        path = Path(path_str)\n",
        "        if path.exists():\n",
        "            files_to_process.append(str(path))\n",
        "            print(f\"‚úÖ Added: {path.name}\")\n",
        "        else:\n",
        "            print(f\"‚ùå Not found: {path_str}\")\n",
        "elif uploaded_files:\n",
        "    files_to_process = uploaded_files\n",
        "    print(\"üì§ Using uploaded files:\")\n",
        "    for f in uploaded_files:\n",
        "        print(f\"  - {Path(f).name}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No files selected. Please upload files or specify file paths.\")\n",
        "\n",
        "print(f\"\\nüìä Ready to process: {len(files_to_process)} file(s)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üöÄ Start Transcription\n",
        "#@markdown Click to start the transcription process\n",
        "\n",
        "start_transcription = True #@param {type:\"boolean\"}\n",
        "\n",
        "if not start_transcription:\n",
        "    print(\"‚è∏Ô∏è Transcription not started. Check the box above to begin.\")\n",
        "elif not files_to_process:\n",
        "    print(\"‚ùå No files to process. Please upload files or specify file paths.\")\n",
        "else:\n",
        "    print(\"üéØ Starting transcription...\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Load model\n",
        "    print(f\"üîÑ Loading {model_size} model...\")\n",
        "    model = faster_whisper.WhisperModel(\n",
        "        model_size,\n",
        "        device=device,\n",
        "        compute_type=compute_type,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "    print(\"‚úÖ Model loaded successfully!\")\n",
        "\n",
        "    # Process each file\n",
        "    for i, file_path in enumerate(files_to_process, 1):\n",
        "        file_path = Path(file_path)\n",
        "        print(f\"\\nüéµ Processing file {i}/{len(files_to_process)}: {file_path.name}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        try:\n",
        "            # Extract audio if video file\n",
        "            if file_path.suffix.lower() in ['.mp4', '.mkv', '.avi', '.mov', '.wmv']:\n",
        "                print(\"üé¨ Extracting audio from video...\")\n",
        "                audio_path = output_dir / f\"{file_path.stem}_audio.wav\"\n",
        "                \n",
        "                # Use ffmpeg to extract audio\n",
        "                (\n",
        "                    ffmpeg\n",
        "                    .input(str(file_path))\n",
        "                    .output(str(audio_path), \n",
        "                           acodec='pcm_s16le', \n",
        "                           ar='16000', \n",
        "                           ac=1,\n",
        "                           vn=None)\n",
        "                    .run(quiet=True, overwrite_output=True)\n",
        "                )\n",
        "                \n",
        "                input_file = str(audio_path)\n",
        "                print(f\"‚úÖ Audio extracted: {audio_path.name}\")\n",
        "            else:\n",
        "                input_file = str(file_path)\n",
        "\n",
        "            # Transcribe\n",
        "            print(\"üéôÔ∏è Transcribing...\")\n",
        "            \n",
        "            segments, info = model.transcribe(\n",
        "                input_file,\n",
        "                language=language if language != \"auto\" else None,\n",
        "                beam_size=5,\n",
        "                patience=2.0,\n",
        "                length_penalty=1.0,\n",
        "                repetition_penalty=1.0,\n",
        "                compression_ratio_threshold=2.4,\n",
        "                logprob_threshold=-1.0,\n",
        "                no_speech_threshold=vad_threshold,\n",
        "                vad_filter=vad_filter,\n",
        "                suppress_blank=True,\n",
        "                suppress_tokens=[-1],\n",
        "                without_timestamps=False,\n",
        "                max_initial_timestamp=1.0,\n",
        "                word_timestamps=True,\n",
        "                prepend_punctuations=\"'\\\"¬ø([{-\",\n",
        "                append_punctuations=\"'.„ÄÇ,Ôºå!ÔºÅ?Ôºü:Ôºö\")]}„ÄÅ\",\n",
        "                initial_prompt=None,\n",
        "                prefix=None,\n",
        "                suppress_numerals=False,\n",
        "                batch_size=batch_size\n",
        "            )\n",
        "\n",
        "            # Collect segments\n",
        "            transcription_segments = []\n",
        "            print(\"üìù Collecting transcription data...\")\n",
        "            \n",
        "            with tqdm(total=None, desc=\"Processing segments\") as pbar:\n",
        "                for segment in segments:\n",
        "                    transcription_segments.append({\n",
        "                        'start': segment.start,\n",
        "                        'end': segment.end,\n",
        "                        'text': segment.text.strip(),\n",
        "                        'words': [\n",
        "                            {\n",
        "                                'word': word.word,\n",
        "                                'start': word.start,\n",
        "                                'end': word.end,\n",
        "                                'probability': word.probability\n",
        "                            } for word in segment.words\n",
        "                        ] if segment.words else []\n",
        "                    })\n",
        "                    pbar.update(1)\n",
        "\n",
        "            # Generate output files\n",
        "            base_name = file_path.stem\n",
        "            \n",
        "            # SRT format\n",
        "            if 'srt' in output_formats:\n",
        "                srt_path = output_dir / f\"{base_name}.srt\"\n",
        "                print(f\"üìÑ Generating SRT: {srt_path.name}\")\n",
        "                \n",
        "                with open(srt_path, 'w', encoding='utf-8') as f:\n",
        "                    for i, segment in enumerate(transcription_segments, 1):\n",
        "                        start_time = f\"{int(segment['start'] // 3600):02d}:{int((segment['start'] % 3600) // 60):02d}:{segment['start'] % 60:05.2f}\"\n",
        "                        end_time = f\"{int(segment['end'] // 3600):02d}:{int((segment['end'] % 3600) // 60):02d}:{segment['end'] % 60:05.2f}\"\n",
        "                        f.write(f\"{i}\\n\")\n",
        "                        f.write(f\"{start_time.replace('.', ',')} --> {end_time.replace('.', ',')}\\n\")\n",
        "                        f.write(f\"{segment['text']}\\n\\n\")\n",
        "                \n",
        "                print(f\"‚úÖ SRT saved: {srt_path}\")\n",
        "\n",
        "            # JSON format\n",
        "            if 'json' in output_formats:\n",
        "                json_path = output_dir / f\"{base_name}.json\"\n",
        "                print(f\"üìÑ Generating JSON: {json_path.name}\")\n",
        "                \n",
        "                import json\n",
        "                output_data = {\n",
        "                    'file': str(file_path),\n",
        "                    'language': info.language,\n",
        "                    'language_probability': info.language_probability,\n",
        "                    'duration': info.duration,\n",
        "                    'segments': transcription_segments\n",
        "                }\n",
        "                \n",
        "                with open(json_path, 'w', encoding='utf-8') as f:\n",
        "                    json.dump(output_data, f, ensure_ascii=False, indent=2)\n",
        "                \n",
        "                print(f\"‚úÖ JSON saved: {json_path}\")\n",
        "\n",
        "            print(f\"‚úÖ Completed: {file_path.name}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing {file_path.name}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"üéâ Transcription completed!\")\n",
        "    print(f\"üìÇ Output files saved in: {output_dir}\")\n",
        "    \n",
        "    # List output files\n",
        "    output_files = list(output_dir.glob(\"*\"))\n",
        "    if output_files:\n",
        "        print(\"\\nüìÑ Generated files:\")\n",
        "        for f in output_files:\n",
        "            print(f\"  - {f.name}\")\n",
        "    \n",
        "    # Download option\n",
        "    print(\"\\nüì• Download options:\")\n",
        "    print(\"- Use the file browser on the left to download individual files\")\n",
        "    print(\"- Or run the download cell below\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üì• Download Results\n",
        "#@markdown Download all output files as a ZIP archive\n",
        "\n",
        "download_results = False #@param {type:\"boolean\"}\n",
        "\n",
        "if download_results:\n",
        "    import shutil\n",
        "    \n",
        "    # Create ZIP archive\n",
        "    zip_path = \"/content/transcription_results.zip\"\n",
        "    shutil.make_archive(\"/content/transcription_results\", 'zip', output_dir)\n",
        "    \n",
        "    # Download\n",
        "    files.download(zip_path)\n",
        "    print(\"‚úÖ ZIP archive downloaded!\")\n",
        "else:\n",
        "    print(\"üìÅ Output files are available in the folder on the left.\")\n",
        "    print(f\"üìÇ Local path: {output_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìñ Usage Instructions\n",
        "\n",
        "## Quick Start:\n",
        "1. **Setup**: Run the first cell to install dependencies\n",
        "2. **Input**: Choose one of the input methods:\n",
        "   - Mount Google Drive for cloud files\n",
        "   - Upload files directly\n",
        "   - Specify local Colab paths\n",
        "3. **Configure**: Adjust settings in the configuration cell\n",
        "4. **Process**: Click the transcription cell to start\n",
        "5. **Download**: Get your results\n",
        "\n",
        "## Supported Formats:\n",
        "- **Audio**: MP3, WAV, FLAC, M4A, OGG\n",
        "- **Video**: MP4, MKV, AVI, MOV, WMV (audio will be extracted)\n",
        "\n",
        "## Tips:\n",
        "- For best Japanese transcription, keep the language set to \"ja\"\n",
        "- Medium model provides the best speed/quality balance\n",
        "- Batch size of 16 works well for most GPUs\n",
        "- Enable VAD filter for better segmentation\n",
        "\n",
        "## Troubleshooting:\n",
        "- If you get CUDA errors, try reducing batch_size\n",
        "- For very long files, consider splitting them first\n",
        "- Check the output logs for detailed error messages"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Faster-Whisper-XXL Optimized Transcription",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
